# Goal

Provide fast, reliable lists of known values for selected **indexed attributes** (e.g., `env`, `region`, `metric.name`, `partner_id`) to power filters, autosuggest, and guardrails in UIs and derivations.

---

# Scope & identity

Decide the scoping keys up front (pick what you’ll filter by most):

* **Minimum**: `attr_key`, `attr_value`
* **Often useful**: `service_id`, `event_type`
* **Optional**: version of the event schema (if you evolve meanings over time)

Keep a small registry of **tracked attributes**, e.g.:

* `event_indexed_attributes(attr_key, is_tracked, notes …)`

---

# Options (from simplest to most robust)

### 1) On-demand DISTINCT (no storage)

* **What:** Query raw events directly whenever a distinct list is needed.
* **Pros:** Zero maintenance; always fresh.
* **Cons:** Slow/expensive at scale; poor UX under load.
* **Use when:** Low volume, prototypes, admin tools.

---

### 2) Materialized views per attribute or event

* **What:** Precompute distinct lists in a view and refresh on a schedule.
* **Pros:** Fast reads; simple to operate.
* **Cons:** Refresh is bulk, not incremental.
* **Use when:** Moderate volume + predictable refresh cadence.

---

### 3) Dictionary tables with periodic batch jobs

* **What:** Maintain a dictionary of values via a background job that scans recent events (e.g., last 60 min) and upserts into the dictionary.
* **Pros:** Cheap incremental cost; fast reads; easy to expire; preserves counts and “last seen.”
* **Cons:** Slight staleness between runs; needs a scheduler.
* **Use when:** Good balance for teams that don’t need sub-minute freshness.

---

### 4) Buffered sets with periodic flush ✅ (preferred)

* **What:** Each node keeps in-memory sets of observed values for tracked attributes during a flush window (e.g., 60s). At flush, values are upserted into the dictionary, then sets are cleared.
* **Pros:**

    * Very fast ingestion, minimal write load.
    * Near-real-time freshness (30–60s typical).
    * Low memory use with caps; predictable cadence.
* **Cons:**

    * Possible loss if a node crashes before flush.
    * Must cap high-cardinality attributes to prevent memory pressure.
* **Cadence guidance:**

    * **Baseline:** flush every 60s.
    * **Adaptive triggers:** flush early if a set exceeds a cap (e.g., 10k values) or global memory budget.
    * **Idle backoff:** skip flushes if no new values; extend to 3–5 min.
    * **Jitter:** ±10% timing jitter per node to avoid synchronized flushes.
    * **Hot vs cold attributes:** hot ones (env, region, metric.name) → 30–60s; cold/high-cardinality (user\_id, url) → 2–5 min or switch to Top-K mode.
* **Use when:** You want freshness within a minute for dashboards/autocomplete, low DB write load, and can tolerate occasional window loss.

---

### 5) Ingestion-path write-through dictionary

* **What:** Update the dictionary immediately as events are ingested.
* **Pros:** Distincts are live within seconds; no batch job needed.
* **Cons:** Adds write overhead to ingest path; must handle retries.
* **Use when:** Absolute real-time distincts are critical and ingest path can absorb the cost.

---

### 6) Windowed dictionaries (time-scoped)

* **What:** Keep rolling “last N days” dictionaries and purge older values.
* **Pros:** Reflects current state; bounded storage; predictable UI lists.
* **Cons:** Loses rare historical values.
* **Use when:** Dashboards only need recent values.

---

### 7) Approximate cardinality / Top-K

* **What:** Maintain sketches (e.g., HyperLogLog for cardinality, Top-K for frequent values).
* **Pros:** Scales to huge domains; very fast for popular values.
* **Cons:** Approximate; doesn’t capture full long tail.
* **Use when:** Attributes like `user_id`, `url`, `request_id` explode in size.

---

### 8) External cache (e.g., Redis)

* **What:** Mirror distinct lists to an external cache; repopulate periodically.
* **Pros:** Ultra-fast UI queries; reduced DB load.
* **Cons:** Extra moving part; cache invalidation required.
* **Use when:** High-traffic filter UIs or autocompletes.

---

### 9) Enums / reference tables for bounded attributes

* **What:** Manage controlled attributes (`env`, `region`, `status`) via enums or reference tables.
* **Pros:** Clean data; instant lists.
* **Cons:** Requires governance to update.
* **Use when:** The attribute set is intentionally controlled.

---

# Operational tips

* **Track only what matters:** Only manage attributes flagged in `event_indexed_attributes`.
* **Scope wisely:** Many UIs want values per service or per event\_type; include those in your dictionary keys.
* **Retention:** Keep `first_seen` / `last_seen` timestamps and purge values not seen for 30–90 days.
* **Guardrails:** If a set explodes in size, cap it and switch to Top-K or require search instead of enumeration.
* **Masking:** Respect privacy rules—never expose masked or sensitive attributes in distincts.
* **Partition awareness:** If raw events are partitioned, batch scans should only read recent partitions.
* **Backfill:** Provide one-time jobs to seed dictionaries from history.

---

# Choosing a path (quick guide)

* **Most teams:** **Option 4 (buffered sets with flush)** is preferred — it balances freshness, low DB load, and simple ops.
* **Absolute accuracy or crash-proofing:** Option 3 (periodic batch jobs).
* **Very high-cardinality attributes:** Option 7 (Approx/Top-K).
* **Bounded domains:** Option 9 (reference tables).
* **High-traffic UIs:** Layer Option 8 (cache) on top.

---
