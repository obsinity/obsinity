### 1. Histogram Frequency (PDF-style)

* After merging, just keep the **per-bucket counts** (`freq[k]`).
* If you want relative frequencies (probabilities):

  $$
  f(k) = \frac{freq[k]}{total}
  $$
* ✅ Works across any arbitrary range because counts add.

---

### 2. Cumulative Distribution Metric (raw cumulative counts)

* Build by cumulative summation:

  $$
  cum[k] = \sum_{i \le k} freq[i]
  $$
* ✅ Still additive, so valid across ranges and shards.

---

### 3. ECDF (normalized cumulative)

* Normalize cumulative counts to total:

  $$
  F(k) = \frac{cum[k]}{total}
  $$
* ✅ Always recompute after merging (never average per-slice ECDFs).

---

### 4. Percentiles (approximate, optional interpolation)

* Use ECDF to find the bucket containing rank `t = p × total`.
* Interpolate inside bucket for higher precision.
* ✅ Arbitrary ranges handled by merging counts before ECDF calculation.

---

### Why this holds across *arbitrary ranges*

* **Associativity:** `freq` counts can be summed across:

    * Time slices (5 s → 1 m → 1 h → 1 d → 7 d).
    * Nodes/shards/partitions.
* Once merged, you rebuild `cum`, `ECDF`, and `percentiles`.
* No loss of correctness (aside from bucket granularity).

---
